{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository import get_dataset\n",
    "\n",
    "from normalizer import GASComplexGaussian\n",
    "from utils import create_dataset_for_mean_layer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset and manipulate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 111)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET THE DATASET\n",
    "DATASET_NAME = \"nn5_weekly\"\n",
    "dataset = get_dataset(DATASET_NAME)\n",
    "len(dataset.train), len(dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save some figures in some folders. Let's initialize folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'figures_from_test_gas/'\n",
    "dataset_folder = root_folder + DATASET_NAME + '/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([el[\"target\"].shape[0] for el in dataset.train]))   # lengths in the train dataset must be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 16, 'W')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_length = dataset.metadata.prediction_length\n",
    "context_length = 2 * prediction_length\n",
    "freq = dataset.metadata.freq\n",
    "\n",
    "prediction_length, context_length, freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm up GAS normalizer (compute static parameters and pre-compute means and variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GASComplexGaussian' object has no attribute 'initial_guesses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/daniele/Desktop/CL_for_timeseries/test_gas_norm_w_monash.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniele/Desktop/CL_for_timeseries/test_gas_norm_w_monash.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m normalizer \u001b[39m=\u001b[39m GASComplexGaussian()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniele/Desktop/CL_for_timeseries/test_gas_norm_w_monash.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# we must warm up the normalizer with the complete list of test time series (test because they are the longest)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/daniele/Desktop/CL_for_timeseries/test_gas_norm_w_monash.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m normalizer\u001b[39m.\u001b[39;49mwarm_up([el[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m el \u001b[39min\u001b[39;49;00m dataset\u001b[39m.\u001b[39;49mtrain], [el[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m el \u001b[39min\u001b[39;49;00m dataset\u001b[39m.\u001b[39;49mtest])   \u001b[39m# normalizer wants list of arrays\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniele/Desktop/CL_for_timeseries/test_gas_norm_w_monash.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m normalizer\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/CL_for_timeseries/normalizer.py:147\u001b[0m, in \u001b[0;36mGASNormalizer.warm_up\u001b[0;34m(self, train_dataset, complete_dataset)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_means_and_vars():\n\u001b[1;32m    144\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    145\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must call the warm_up method only once before using the normalizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m     )\n\u001b[0;32m--> 147\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_static_parameters(train_dataset)\n\u001b[1;32m    149\u001b[0m \u001b[39m# we must check if mean_0 and var_0 are initialized\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m# if not, we initialize them as mean and var of the time series\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m# they must have the same shape of means and vars, i.e., lists of 2D tensors\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeans_0) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/CL_for_timeseries/normalizer.py:394\u001b[0m, in \u001b[0;36mGASComplexGaussian.compute_static_parameters\u001b[0;34m(self, ts)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneg_log_likelihood_Gaussian(\n\u001b[1;32m    388\u001b[0m         ts, alpha_mean, alpha_sigma, mean_0, var_0\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m ts_i \u001b[39min\u001b[39;00m ts:\n\u001b[1;32m    392\u001b[0m     optimal \u001b[39m=\u001b[39m minimize(\n\u001b[1;32m    393\u001b[0m         \u001b[39mlambda\u001b[39;00m params: minimization_funct(ts_i, \u001b[39m*\u001b[39mparams),\n\u001b[0;32m--> 394\u001b[0m         x0\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_guesses,\n\u001b[1;32m    395\u001b[0m         bounds\u001b[39m=\u001b[39mbounds,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[1;32m    397\u001b[0m     alpha_mean, alpha_sigma, mean_0, sigma2_0 \u001b[39m=\u001b[39m optimal\u001b[39m.\u001b[39mx\n\u001b[1;32m    398\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha_means\u001b[39m.\u001b[39mappend(alpha_mean)\n",
      "File \u001b[0;32m~/Desktop/CL_for_timeseries/cl_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GASComplexGaussian' object has no attribute 'initial_guesses'"
     ]
    }
   ],
   "source": [
    "normalizer = GASComplexGaussian()\n",
    "# we must warm up the normalizer with the complete list of test time series (test because they are the longest)\n",
    "initial_guesses = np.array([0.001, 0.001, 0, 1])\n",
    "bounds = ((None, None), (0.00001, 1), (0, 1), (0, 1))\n",
    "normalizer.warm_up([el['target'] for el in dataset.train], [el['target'] for el in dataset.test], initial_guessesm bounds)   # normalizer wants list of arrays\n",
    "\n",
    "normalizer.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, _ = normalizer.get_means_and_vars()\n",
    "tr_means = [m[:-prediction_length] for m in means]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series as well as means computed by GAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means[0].shape, list(dataset.test)[0]['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_0 = list(dataset.test)[0][\"target\"]\n",
    "mean_0 = means[0].squeeze()\n",
    "\n",
    "ts_len = ts_0.shape[0]\n",
    "\n",
    "plt.plot(range(ts_len), ts_0, label=\"original\")\n",
    "plt.plot(range(ts_len), mean_0, label=\"mean\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ts_train_list = normalizer.normalize([el['target'] for el in dataset.train])   # normalizer wants list of arrays\n",
    "norm_ts_test_list = normalizer.normalize([el['target'] for el in dataset.test])\n",
    "norm_ts_train_list[0].shape, norm_ts_test_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ts_test_0 = norm_ts_test_list[0]\n",
    "len_ts = norm_ts_test_0.shape[0]\n",
    "\n",
    "plt.plot(range(len_ts), ts_0, label=\"original\")\n",
    "plt.plot(range(len_ts), norm_ts_test_0, label=\"normalized\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ts_test_0 = norm_ts_test_list[0]\n",
    "len_ts = norm_ts_test_0.shape[0]\n",
    "\n",
    "plt.plot(range(len_ts), norm_ts_test_0, label=\"normalized\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train mean layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAINING_SAMPLES_PER_TS = 10\n",
    "N_TEST_SAMPLES_PER_TS = 10\n",
    "\n",
    "list_train_ts = [el['target'] for el in dataset.train]\n",
    "list_test_ts = [el['target'] for el in dataset.test]\n",
    "list_train_mean = [el.squeeze() for el in tr_means]   # squeeze just to be sure its shape is (ts_len,)\n",
    "list_test_mean = [el.squeeze() for el in means]   # squeeze just to be sure its shape is (ts_len,)\n",
    "\n",
    "train_means_xs, train_means_ys = create_dataset_for_mean_layer(list_train_ts, list_train_mean, context_length, prediction_length, N_TRAINING_SAMPLES_PER_TS)\n",
    "test_means_xs, test_means_ys = create_dataset_for_mean_layer(list_test_ts, list_test_mean, context_length, prediction_length, N_TEST_SAMPLES_PER_TS)\n",
    "\n",
    "train_means_xs.shape, train_means_ys.shape, test_means_xs.shape, test_means_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_means_xs, train_means_ys)\n",
    "\n",
    "regr.score(test_means_xs, test_means_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the predicted time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ts_list = []\n",
    "\n",
    "for ts, mean_ts in zip(list_test_ts, list_test_mean):\n",
    "    ts_len = ts.shape[0]\n",
    "\n",
    "    pred_ts = []\n",
    "    # first context_length values are the means\n",
    "    pred_ts.extend(mean_ts[:context_length].tolist())\n",
    "    # then we predict only the following elements\n",
    "    for i in range(context_length, ts_len - prediction_length):\n",
    "        pred_ts.append(regr.predict(mean_ts[i-context_length:i].reshape(1, -1))[0][0])\n",
    "    # at the end we predict the last prediction_length elements\n",
    "    pred_ts.extend(regr.predict(mean_ts[-context_length:].reshape(1, -1))[0].tolist())\n",
    "    pred_ts_list.append(pred_ts)\n",
    "\n",
    "pred_ts_list = np.array(pred_ts_list)\n",
    "pred_ts_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_0 = list_test_ts[0]\n",
    "mean_0 = list_test_mean[0]\n",
    "pred_0 = pred_ts_list[0]\n",
    "len_ts = ts_0.shape[0]\n",
    "\n",
    "plt.plot(range(len_ts), ts_0, label=\"original\")\n",
    "plt.plot(range(len_ts), mean_0, label=\"mean\")\n",
    "plt.plot(range(len_ts), pred_0, label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and save the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an example of the final figure\n",
    "ts_0 = list_test_ts[0]\n",
    "mean_0 = list_test_mean[0]\n",
    "pred_0 = pred_ts_list[0]\n",
    "norm_0 = norm_ts_test_list[0]\n",
    "\n",
    "len_ts = ts_0.shape[0]\n",
    "\n",
    "fig, axis = plt.subplots(5, 1, figsize=(15, 10))\n",
    "\n",
    "axis[0].plot(range(ts_len), ts_0, label=\"original\")\n",
    "axis[0].plot(range(ts_len), mean_0, label=\"mean\")\n",
    "axis[0].legend()\n",
    "axis[0].set_title(\"Original and mean\")\n",
    "\n",
    "axis[1].plot(range(ts_len), mean_0, label=\"mean\")\n",
    "axis[1].legend()\n",
    "axis[1].set_title(\"Mean\")\n",
    "\n",
    "axis[2].plot(range(ts_len), ts_0, label=\"original\")\n",
    "axis[2].plot(range(ts_len), norm_0, label=\"mean\")\n",
    "axis[2].legend()\n",
    "axis[2].set_title(\"Original and normalized\")\n",
    "\n",
    "axis[3].plot(range(ts_len), norm_0, label=\"mean\")\n",
    "axis[3].legend()\n",
    "axis[3].set_title(\"Normalized\")\n",
    "\n",
    "axis[4].plot(range(ts_len), ts_0, label=\"original\")\n",
    "axis[4].plot(range(ts_len), mean_0, label=\"mean\")\n",
    "axis[4].plot(range(ts_len), pred_0, label=\"prediction\")\n",
    "axis[4].legend()\n",
    "axis[4].set_title(\"Original, mean and prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max number of figures to be saved\n",
    "MAX_FIG = 20\n",
    "# select randomly MAX_FIG figures to make\n",
    "idxs = np.random.choice(len(list_test_ts), MAX_FIG, replace=False)\n",
    "\n",
    "for idx in idxs:\n",
    "    ts_i = list_test_ts[idx]\n",
    "    mean_i = list_test_mean[idx]\n",
    "    pred_i = pred_ts_list[idx]\n",
    "    norm_i = norm_ts_test_list[idx]\n",
    "\n",
    "    ts_len = ts_i.shape[0]\n",
    "\n",
    "    fig, axis = plt.subplots(5, 1, figsize=(15, 10))\n",
    "\n",
    "    axis[0].plot(range(ts_len), ts_i, label=\"original\")\n",
    "    axis[0].plot(range(ts_len), mean_i, label=\"mean\")\n",
    "    axis[0].legend()\n",
    "    axis[0].set_title(\"Original and mean\")\n",
    "\n",
    "    axis[1].plot(range(ts_len), mean_i, label=\"mean\")\n",
    "    axis[1].legend()\n",
    "    axis[1].set_title(\"Mean\")\n",
    "\n",
    "    axis[2].plot(range(ts_len), ts_i, label=\"original\")\n",
    "    axis[2].plot(range(ts_len), norm_i, label=\"mean\")\n",
    "    axis[2].legend()\n",
    "    axis[2].set_title(\"Original and normalized\")\n",
    "\n",
    "    axis[3].plot(range(ts_len), norm_i, label=\"mean\")\n",
    "    axis[3].legend()\n",
    "    axis[3].set_title(\"Normalized\")\n",
    "\n",
    "    axis[4].plot(range(ts_len), ts_i, label=\"original\")\n",
    "    axis[4].plot(range(ts_len), mean_i, label=\"mean\")\n",
    "    axis[4].plot(range(ts_len), pred_i, label=\"prediction\")\n",
    "    axis[4].legend()\n",
    "    axis[4].set_title(\"Original, mean and prediction\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dataset_folder + f'ts_{idx}.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
